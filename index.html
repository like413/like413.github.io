<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="robots" content="index, follow" />
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="keywords" content="Ke Li, 李柯, Remote Sensing, Image Processing, Deep Learning, Multi-Modality, Xidian University">
<link rel="stylesheet" href="./Files/jemdoc.css" type="text/css" />
<script src="jquery.min.js"></script>
<link rel="shortcut icon" href="./Files/favicon.ico">
<title>Ke Li's Homepage</title>
</head>

<body>

<a id="home" class="anchor"></a>
<div id="container"> 
<div class="container"> 

<table class="imgtable"><tr><td>
<a href="./"><img src="./Files/like-life.png" alt="" height="215px" /></a>&nbsp;</td>
<td align="left"><p><a href="./"><font size="4">Ke Li(</font><font size="4"; font style="font-family:Microsoft YaHei">李柯-西安电子科技大学</font><font size="4">)</font></a><br />
<i>Ph.D Student (2023 ~ Now)</i>
<br /><br />
 
<a href="https://cs.xidian.edu.cn/ztwz/z2024yzzt/sy/qrsjsjsyjs/ky.htm" target="_blank">Key Laboratory of Smart Human-Computer Interaction and Wearable Technology of Shaanxi Province</a><br />
<a href="https://www.xidian.edu.cn/" target="_blank">Xidian University</a><br />
<br />
Email: like0413@stu.xidian.edu.cn <br />
[<a href="https://github.com/like413" target="_blank">GitHub</a>] 
[<a href="https://scholar.google.com/citations?user=xidIhU0AAAAJ&hl=zh-CN" target="_blank">GoogleScholar</a>] 
[<a href="https://orcid.org/my-orcid?orcid=0000-0003-2873-7795" target="_blank">ORCID</a>] 
 
<br />
<br />
 Location: 266 Xinglong Section of Xifeng Road, Xi'an, Shaanxi, China 710126<br />
<class="staffshortcut">
 <A HREF="#News">News</A> | 
 <A HREF="#Interest">Research Interest</A> | 
 <!-- <A HREF="#Co-authors">Co-authors</A> | -->
 <!-- <A HREF="#Education">Education</A> |  -->
 <A HREF="#Publications">Publications</A> | 
 <A HREF="#Membership">Membership</A> | 
 <A HREF="#Reviewer">Reviewer</A> | 
 <A HREF="#Awards">Awards</A>|
 <A HREF="#Conference Experience">Conference Experience</A>|

</td></tr></table>

<A NAME="News"><h2>News</h2></A>
<div class="news" style="overflow:auto; height:150px; Width:99%;">
 <ul>
 <li>[01, 2025]&nbsp;&nbsp;&nbsp; Several papers accepted, 1 <h7>IEEE IoT</h7>, 1 <h7>PRL</h7>.</li>
 <li>[12, 2024]&nbsp;&nbsp;&nbsp; 1 papers accepted to <h7 style="color: #f44597;">AAAI 2025</h7>.</li>
 <li>[11, 2024]&nbsp;&nbsp;&nbsp; 1 papers accepted to <h7 style="color: #f44597;">IEEE TIFS</h7>.</li>
 <li>[08, 2024]&nbsp;&nbsp;&nbsp; 1 papers accepted to <h7>NN</h7>.</li>
 <li>[07, 2024]&nbsp;&nbsp;&nbsp; Several papers accepted, 1 <h7>IEEE TGRS</h7>, 1 <h7>PR</h7>, 3 <h7>IGARSS 2024</h7>.</li>
 <li>[06, 2024]&nbsp;&nbsp;&nbsp; 1 papers accepted to <h7 style="color: #f44597;">CVPR 2024</h7>.</li>
 <li>[04, 2024]&nbsp;&nbsp;&nbsp; 1 papers accepted to <h7>IEEE GRSL</h7>.</li>
 <li>[03, 2024]&nbsp;&nbsp;&nbsp; 1 papers accepted to <h7>IEEE JSTARS</h7>.</li>
 <li>[02, 2024]&nbsp;&nbsp;&nbsp; 1 papers accepted to <h7>ESWA</h7>.</li>                
 <li>[08, 2023]&nbsp;&nbsp;&nbsp; 1 papers accepted to <h7>IEEE TGRS</h7>.</li>
 <li>[06, 2023]&nbsp;&nbsp;&nbsp; 1 papers accepted to <h7>BSPC</h7>.</li>
 </ul>
</div><br>        

 
<!-- <A NAME="News"><h2>News</h2></A>
<ul>
 <li> <b> <font color="#FF0000">[2024.06]</font> </b>The biggest Hyperspectral foundation model <b>HyperSIGMA</b> has been released at Arxiv [<a href="https://arxiv.org/abs/2406.11519">Paper</a>][<a href="https://github.com/WHU-Sigma/HyperSIGMA">Code</a>]!
 <li> <b> <font color="#FF0000">[2024.06]</font> </b> I am gonna to a postdoc at Sun Yat-sen University !</li>
 <li> <b> <font color="#FF0000">[2024.05]</font> </b> One paper has been accepted by <b>ISPRS</b> (<a href="https://www.sciencedirect.com/science/article/pii/S0924271624001539" target="_blank">link</a>)!</li>
 <li> <b> <font color="#FF0000">[2024.02]</font> </b> One co-authored paper has been accepted by <b>IEEE TGRS</b> (<a href="https://ieeexplore.ieee.org/document/10445496" target="_blank">link</a>)!</li>
 <li> <b> <font color="#FF0000">[2023.10]</font> </b> One co-authored paper has been accepted by <b>IEEE JSTARS</b> (<a href="https://ieeexplore.ieee.org/abstract/document/10285305" target="_blank">link</a>)!</li>
 <li> <b> <font color="#FF0000">[2023.09]</font> </b> One co-authored paper has been accepted by <b>IEEE JSTARS</b> (<a href="https://ieeexplore.ieee.org/document/10234560" target="_blank">link</a>)!</li>
 <li> <b> <font color="#FF0000">[2023.04]</font> </b> One co-authored paper has been accepted by <b>IEEE JSTARS</b> (<a href="https://ieeexplore.ieee.org/abstract/document/10093022" target="_blank">link</a>)!</li>
 <li> <b> <font color="#FF0000">[2023.04]</font> </b> One paper is acceptted as a <b>Poster</b> by <b>IGARSS 2023</b> (<a href="https://2023.ieeeigarss.org/papers/accepted_papers.php" target="_blank">homepage)</a>!</li>

</ul>
<br /> -->


 
<A NAME="Interest"><h2>Research Interest</h2></A>
I am working in Remote Sensing; Deep learning; Computer Vision; Multi-Modal Representation. Currently, I focus on the following research topics:
<ul>
<li>Multi-Modal Remote Sensing Imagery Interpretation</li>
<li>Remote Sensing Object Detection</li>
<li>Muti-Source Fusion</li>
</ul>
<br />


<A NAME="Publications"><h2>Publications</h2></A>

<p><b>Conferences</b>: </p>
<font size="3"> 
<ul>
</ul>
</font>

 <p></p>
<font size="3"> 
<ul>

<table width="100%" class="imgtable">
    <tr>
        <td width="306"> <img src="Files/CVD.jpg" width="290px"></td>
        <td>
            <a href="https://arxiv.org/abs/2505.11822">[7] Robust Cross-View Geo-Localization via Content-Viewpoint Disentanglement</a>
            <br> <b>Ke Li</b>, Di Wang, Xiaowei Wang, Zhihong Wu, Yiming Zhang, Yifeng Wang, Quan Wang
            <br><i>arXiv preprint arXiv</i>, 2025. 
            <br>[<a href="https://arxiv.org/abs/2505.11822">Paper</a>]
        </td>
    </tr>
</table>
<br />
    
<table width="100%" class="imgtable">
    <tr>
        <td width="306"> <img src="Files/FD2-Net.jpg" width="290px"></td>
        <td>
            <a href="">[6] FD2-Net: Frequency-Driven Feature Decomposition Network for Infrared-Visible Object Detection</a>
            <br> <b>Ke Li</b>, Di Wang, Zhangyuan Hu, Shaofeng Li, Weiping Ni, Lin Zhao, Quan Wang
            <br><i>The 39th Annual AAAI Conference on Artificial Intelligence (<b>AAAI</b>)</i>, 2025. (<b>CCF-A</b>) 
            <br>[<a href="https://arxiv.org/abs/2412.09258">Paper</a>]
        </td>
    </tr>
</table>
<br />

<table width="100%" class="imgtable">
    <tr>
        <td width="306"> <img src="Files/CDQAG.jpg" width="290px"></td>
        <td>
            <a href="">[5] Show Me What and Where has Changed? Question Answering and Grounding for Remote Sensing Change Detection</a> ;
            <br> <b>Ke Li</b>, Fuyu Dong, Di Wang, Shaofeng Li, Quan Wang, Xinbo Gao, Tat-Seng Chua
            <br><i>arXiv preprint arXiv</i>, 2024. 
            <br>[<a href="https://like413.github.io/CDQAG/">Project Page</a>][<a href="https://arxiv.org/abs/2410.23828">Paper</a>][<a href="https://github.com/like413/VisTA">Dataset and Code</a>]
        </td>
    </tr>
</table>
<br />

<table width="100%" class="imgtable">
    <tr>
        <td width="306"> <img src="Files/TPAP.jpg" width="290px"></td>
        <td>
            <a href="https://www.2024.ieeeigarss.org/papers/accepted_papers.php">[4] Transferable Physical Adversarial Patch Attacks for Remote Sensing Object Detection</a>
            <br> Di Wang, Wenxuan Zhu, <b>Ke Li</b>, Xiao Gao, Pengfei Yang
            <br><i>Proceeding of the IEEE International Geoscience and Remote Sensing Symposium (<b>IGARSS 2024</b>)</i>, 2024. (<b>EI</b>) 
            <br>[<a href="https://ieeexplore.ieee.org/document/10640565">Paper</a>]
        </td>
    </tr>
</table>
<br />

<table width="100%" class="imgtable">
    <tr>
        <td width="306"> <img src="Files/KANet.jpg" width="290px"></td>
        <td>
            <a href="https://www.2024.ieeeigarss.org/papers/accepted_papers.php">[3] Kernel-Adaptive Change Detection Network in Remote Sensing Imagery</a>
            <br> Di Wang , Fuyu Dong, <b>Ke Li</b>, and Duo Chen
            <br><i>Proceeding of the IEEE International Geoscience and Remote Sensing Symposium (<b>IGARSS 2024</b>)</i>, 2024. (<b>EI</b>) 
            <br>[<a href="https://ieeexplore.ieee.org/document/10641785">Paper</a>]
        </td>
    </tr>
</table>
<br />

<table width="100%" class="imgtable">
    <tr>
        <td width="306"> <img src="Files/RSVQA.jpg" width="290px"></td>
        <td>
            <a href="https://www.2024.ieeeigarss.org/papers/accepted_papers.php">[2] Alignment and Multimodal Reasoning for Remote Sensing Visual Question Answering</a>
            <br> Yumin Tian, Haojie Xu, Di Wang, <b>Ke Li</b>, and Lin Zhao
            <br><i>Proceeding of the IEEE International Geoscience and Remote Sensing Symposium (<b>IGARSS 2024</b>)</i>, 2024. (<b>EI</b>) 
            <br>[<a href="https://ieeexplore.ieee.org/document/10641340">Paper</a>]
        </td>
    </tr>
</table>
<br />

<table width="100%" class="imgtable">
    <tr>
        <td width="306"> <img src="Files/SFS-Conv.jpg" width="290px"></td>
        <td>
            <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Li_Unleashing_Channel_Potential_Space-Frequency_Selection_Convolution_for_SAR_Object_Detection_CVPR_2024_paper.pdf">[1] Unleashing Channel Potential: Space-Frequency Selection Convolution for SAR Object Detection</a>
            <br> <b>Ke Li</b>, Di Wang, Zhangyuan Hu, Wenxuan Zhu, Shaofeng Li, Quan Wang
            <br><i>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>)</i>, 2024. (<b>CCF-A</b>) 
            <br>[<a href="https://openaccess.thecvf.com/content/CVPR2024/html/Li_Unleashing_Channel_Potential_Space-Frequency_Selection_Convolution_for_SAR_Object_Detection_CVPR_2024_paper.html">Paper</a>][<a href="https://github.com/like413/SFS-Conv">Code</a>][<a href="https://cvpr.thecvf.com/media/PosterPDFs/CVPR%202024/31673.png?t=1717081744.6876934">Poster</a>]
        </td>
    </tr>
</table>
<br /> 

</ul>

</ul>
<p></p>

<p><b>Journals</b>: </p>
<font size="3"> 
<ul>

</ul>
</font>


 <p></p>
<font size="3"> 
<ul>

<table width="100%" class="imgtable">
<tr>
    <td width="306"> <img src="Files/PatchGen.jpg" width="290px"></td>
    <td>
        <a href="https://ieeexplore.ieee.org/document/10795220">[9] Physical Adversarial Patch Attack for Optical Fine-grained Aircraft Recognition</a>
        <br><b>Ke Li</b>, Di Wang, Wenxuan Zhu, Shaofeng Li, Quan Wang, Xinbo Gao
        <br><i> IEEE Transactions on Information Forensics and Security (<b>TIFS</b>)</i>, 2024. (<b>CCF-A, SCI Q1 TOP, IF=6.3</b>)
        <br>[<a href="https://ieeexplore.ieee.org/document/10795220">Paper</a>]
    </td>
</tr>
</table>
<br />

<table width="100%" class="imgtable">
<tr>
    <td width="306"> <img src="Files/DiagSwin.jpg" width="290px"></td>
    <td>
        <a href="https://www.sciencedirect.com/science/article/pii/S089360802400577X?via%3Dihub">[8] DiagSWin: A Multi-Scale Vision Transformer with Diagonal-Shaped Windows for Object Detection and Segmentation</a>
        <br><b>Ke Li</b>, Di Wang, Gang Liu, Wenxuan Zhu, Haodi Zhong, Quan Wang
        <br><i> Neural Networks (<b>NN</b>)</i>, 2024. (<b>SCI Q1 TOP, IF=6.0</b>)
        <br>[<a href="https://www.sciencedirect.com/science/article/pii/S089360802400577X?via%3Dihub">Paper</a>]
    </td>
</tr>
</table>
<br />
 
<table width="100%" class="imgtable">
<tr>
    <td width="306"> <img src="Files/GR-GAN.jpg" width="290px"></td>
    <td>
        <a href="https://www.sciencedirect.com/science/article/pii/S0031320324005661">[7] GR-GAN: A Unified Adversarial Framework for Single Image Glare Removal and Denoising</a>
        <br>Cong Niu, <b>Ke Li</b>, Di Wang, Wenxuan Zhu, Haojie Xu, Jinhui Dong
        <br><i> Pattern Recognition (<b>PR</b>)</i>, 2024. (<b>SCI Q1 TOP, IF=7.5</b>)
        <br>[<a href="https://www.sciencedirect.com/science/article/pii/S0031320324005661">Paper</a>]
    </td>
</tr>
</table>
<br />

<table width="100%" class="imgtable">
<tr>
    <td width="306"> <img src="Files/LPVA.jpg" width="290px"></td>
    <td>
        <a href="https://ieeexplore.ieee.org/abstract/document/10584552">[6] Language-Guided Progressive Attention for Visual Grounding in Remote Sensing Images</a> ;
        <br><b>Ke Li</b>, Di Wang, Haojie Xu, Haodi Zhong, Cong Wang
        <br><i> IEEE Transactions on Geoscience and Remote Sensing (<b>TGRS</b>)</i>, 2024. (<b>SCI Q1, IF=7.5</b>)
        <br>[<a href="https://like413.github.io/OPT-RSVG/">Project Page</a>][<a href="https://ieeexplore.ieee.org/abstract/document/10584552">Paper</a>][<a href="https://github.com/like413/OPT-RSVG">Dataset and Code</a>]
    </td>
</tr>
</table>
<br />

<table width="100%" class="imgtable">
<tr>
    <td width="306"> <img src="Files/ESWA.jpg" width="290px"></td>
    <td>
        <a href="https://www.sciencedirect.com/science/article/pii/S0957417424002628">[5] Multi-Object Behavior Recognition based on Object Detection for Dense Crowds</a>
        <br>Min Dang, Gang Liu, Qijie Xu, <b>Ke Li</b>, Di Wang, Lihuo He
        <br><i> Expert Systems with Applications (<b>ESWA</b>)</i>, 2024. (<b>SCI Q1 TOP, IF=8.5</b>)
        <br>[<a href="https://www.sciencedirect.com/science/article/pii/S0957417424002628">Paper</a>]
    </td>
</tr>
</table>
<br />

<table width="100%" class="imgtable">
<tr>
    <td width="306"> <img src="Files/VSMR.jpg" width="290px"></td>
    <td>
        <a href="https://ieeexplore.ieee.org/abstract/document/10494585">[4] Visual Selection and Multistage Reasoning for RSVG</a>
        <br>Yueli Ding, Haojie Xu, Di Wang, <b>Ke Li</b>, Yumin Tian
        <br><i> IEEE Geoscience and Remote Sensing Letters (<b>GRSL</b>)</i>, 2024. (<b>SCI Q2, IF=4.8</b>)
        <br>[<a href="https://ieeexplore.ieee.org/abstract/document/10494585">Paper</a>]
    </td>
</tr>
</table>
<br />

<table width="100%" class="imgtable">
<tr>
    <td width="306"> <img src="Files/MSSARFNet.jpg" width="290px"></td>
    <td>
        <a href="https://ieeexplore.ieee.org/abstract/document/10476640">[3] Multi-Scale Spectral-Spatial Attention Residual Fusion Network for Multi-Source Remote Sensing Data Classification</a>
        <br>Xu Wang, Gang Liu, <b>Ke Li</b>, Min Dang, Di Wang, Zili Wu, Rong Pan
        <br><i> IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing (<b>JSTARS</b>)</i>, 2024. (<b>SCI Q2 TOP, IF=5.5</b>)
        <br>[<a href="https://ieeexplore.ieee.org/abstract/document/10476640">Paper</a>]
    </td>
</tr>
</table>
<br />

<table width="100%" class="imgtable">
<tr>
    <td width="306"> <img src="Files/RuotongXiang.jpg" width="290px"></td>
    <td>
        <a href="https://www.sciencedirect.com/science/article/abs/pii/S1746809423005608">[2] Zero-Watermark Scheme for Medical Image Pprotection based on Style Feature and ResNet</a>
        <br>Ruotong Xiang, Gang Liu, <b>Ke Li</b>, Jing Liu, Ziyi Zhang, Min Dang
        <br><i>Biomedical Signal Processing and Control (<b>BSPC</b>)</i>, 2023. (<b>SCI Q2, IF=5.1</b>) 
        <br>[<a href="https://www.sciencedirect.com/science/article/abs/pii/S1746809423005608">Paper</a>]
    </td>
</tr>
</table>
<br />

<table width="100%" class="imgtable">
<tr>
    <td width="306"> <img src="Files/MACN.jpg" width="290px"></td>
    <td>
        <a href="https://ieeexplore.ieee.org/abstract/document/10236462">[1] Mixing Self-Attention and Convolution: A Unified Framework for Multisource Remote Sensing Data Classification</a>
        <br><b>Ke Li</b>, Di Wang, Xu Wang, Gang Liu, Zili Wu, Quan Wang
        <br><i>IEEE Transactions on Geoscience and Remote Sensing (<b>TGRS</b>)</i>, 2023. (<b>SCI Q1 TOP, IF=8.2</b>) 
        <br>[<a href="https://ieeexplore.ieee.org/abstract/document/10236462">Paper</a>][<a href="https://github.com/like413/MACN">Code</a>]
    </td>
</tr>
</table>
<br />

 
<br />
</ul>
</font>

<p></p>


<A NAME="Membership"><h2>Membership</h2></A>
<font size="3"> 
<ul>
<li>Computer Vision Foundation (CVF), Student Member</li>
<li>IEEE Geoscience and Remote Sensing Society (GRSS), Student Member</li>
<li>IEEE, Student Member</li>

</ul>
</font>
<br />
<p></p>
<br />
</ul>
</font>

<p></p>

<A NAME="Reviewer"><h2>Journal/Conference Reviewer</h2></A>
<font size="3"> 
<ul>
<li><a href="https://iccv.thecvf.com/">International Conference on Computer Vision (<b>ICCV 2025</b>)</li>
<li><a href="https://www.editorialmanager.com/inffus/Default.aspx?pg=login.asp%3floginError%3d1%26username%3dKeLi990413">Information Fusion (<b>Inform. Fusion</b>)</li>
<li><a href="https://taylorandfrancis.com/">International Journal of Digital Earth (<b>TJDE</b>)</li>
<li><a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=36">IEEE Transactions on Geoscience and Remote Sensing (<b>TGRS</b>)</li>
<li><a href="https://iclr.cc/Conferences/2025">The Thirteenth International Conference on Learning Representations (<b>ICLR 2025</b>)</li>
<li><a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=76">IEEE Transactions on Circuits and Systems for Video Technology (<b>TCSVT</b>)</li>
<li><a href="https://www.editorialmanager.com/bspc/Default.aspx">Biomedical Signal Processing and Control (<b>BSPC</b>)</li>
</ul>
</font>
<br />

</ul>
</font>
<br />
</ul>
<br />
 
 
<A NAME="Awards"><h2>Awards</h2></A>
<font size="3"> 
<ul>
<li>2025.04, &nbsp;First Prize of Academic Scholarship, Xidian University | <font style="font-family:Microsoft YaHei">西安电子科技大学 学业奖学金一等奖</font></li>
<li>2025.01, &nbsp;Tencent Scholarship, Xidian University | <font style="font-family:Microsoft YaHei">西安电子科技大学 腾讯奖学金特等奖</font></li>
<li>2024.05, &nbsp;First Prize of Academic Scholarship, Xidian University | <font style="font-family:Microsoft YaHei">西安电子科技大学 学业奖学金一等奖</font></li>
<li>2023.12, &nbsp;Tencent Scholarship, Xidian University | <font style="font-family:Microsoft YaHei">西安电子科技大学 腾讯奖学金</font></li>
<li>2023.05, &nbsp;Second Prize of Academic Scholarship, Xidian University | <font style="font-family:Microsoft YaHei">西安电子科技大学 学业奖学金二等奖</font></li>
<li>...</li>

 
<br />

</ul>
</font>



<br />
<br />
 
<A NAME="Conference Experience"><h2>Conference Experience</h2></A>
<font size="3"> 
<ul>
<li>2025年6月13-15日, <a href= "https://yb.cie.org.cn/" target="_blank"><u>赴杭州参加中国电子学会优博论坛, 2025</u></a>  </li>
<li>2025年6月6-8日, <a href= "https://valser.org/2025/#/" target="_blank"><u>赴珠海参加第十五届视觉与学习青年学者研讨会, VALSE 2025</u></a>  </li>
<li>2024年6月16-22日, <a href= "https://cvpr.thecvf.com/" target="_blank"><u>赴美国西雅图参加第四十一届国际计算机视觉与模式识别会议, CVPR 2024</u></a>  </li>
<li>2024年5月5-7日, <a href= "https://valser.org/2024/#/" target="_blank"><u>赴重庆参加第十四届视觉与学习青年学者研讨会, VALSE 2024</u></a>  </li>
<li>2023年12月28-31日, <a href= "http://youth.csig.org.cn/CSIG2023/" target="_blank"><u>赴广州参加第十九届中国图像图形学学会青年科学家会议, 2023</u></a>  </li>
<li>2023年10月13-15日, <a href= "http://prcv2023.xmu.edu.cn" target="_blank"><u>赴厦门参加第六届中国模式识别与计算机视觉大会, PRCV 2023</u></a>  </li>  

<div id="article"></div>
<div id="back_top">
<div class="arrow"></div>
<div class="stick"></div>
</div>

<script>
$(function(){
    $(window).scroll(function(){  //If scroll
        var scrollt = document.documentElement.scrollTop + document.body.scrollTop; //Getting Height after scroll
        if( scrollt >400 )
        {  
            $("#back_top").fadeIn(400); 
        }
        else
        {
            $("#back_top").stop().fadeOut(400);
        }
    });

    $("#back_top").click(function(){ 

        $("html,body").animate({scrollTop:"0px"}, 200);

    }); 

});
</script>

 
</body>
</html>
